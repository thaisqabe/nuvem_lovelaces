{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMVAF1F1WHZ9h17QVqkuUs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thaisqabe/nuvem_lovelaces/blob/main/analiselovelaces.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('nuvemlovelace.xlsx')\n",
        "mascara = np.array(Image.open('nuvem.jpg'))"
      ],
      "metadata": {
        "id": "ygx6Z7S5mgzg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import pandas as pd\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "# Carregar as stopwords do NLTK\n",
        "stop_words = set(stopwords.words('portuguese'))\n",
        "\n",
        "stopwords_personalizadas = set(['a', 'agora', 'algum', 'alguma', 'aquele', 'aqueles', 'de', 'deu', 'do',\n",
        "                                 'e', 'estou', 'esta', 'ir', 'meu', 'muito', 'mesmo', 'no', 'nossa',\n",
        "                                 'o', 'outro', 'para', 'que', 'sem', 'tem', 'porque', 'não', 'acredito'])\n",
        "\n",
        "# Combinar stopwords do NLTK com stopwords personalizadas\n",
        "todas_stopwords = stop_words.union(stopwords_personalizadas)\n",
        "\n",
        "\n",
        "\n",
        "# Carregar os dados do Excel\n",
        "df = pd.read_excel('nuvemlovelace.xlsx')\n",
        "\n",
        "# Verificar se a coluna \"frases\" existe\n",
        "if 'frases' in df.columns:\n",
        "    # Concatenar todas as frases em uma única string\n",
        "    texto = ' '.join(df['frases'].dropna().astype(str).tolist())\n",
        "\n",
        "    # Remover stopwords\n",
        "    palavras = [word for word in texto.split() if word.lower() not in todas_stopwords]\n",
        "    texto_sem_stopwords = ' '.join(palavras)\n",
        "\n",
        "\n",
        "    # Carregar a imagem de máscara\n",
        "    mascara = np.array(Image.open('mulhernuvem.png'))\n",
        "\n",
        "    # Gerar a nuvem de palavras com a máscara\n",
        "    wordcloud = WordCloud(width=1000, height=5000,\n",
        "                          background_color='white',\n",
        "                          mask=mascara,\n",
        "                          contour_color='pink',\n",
        "                          contour_width=1).generate(texto_sem_stopwords)\n",
        "\n",
        "    # Exibir a nuvem de palavras\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis('off')  # Remove os eixos\n",
        "    plt.show()\n",
        "\n",
        "    # Salvar a nuvem de palavras em um arquivo\n",
        "    wordcloud.to_file('nuvem_de_palavras.png')\n",
        "else:\n",
        "    print(\"A coluna 'frases' não foi encontrada na planilha.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9U0P-C-VyRCz",
        "outputId": "1fce9f85-0d30-417e-91ed-3f5a5ec4b5aa"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "# Carregar as stopwords do NLTK\n",
        "stop_words = set(stopwords.words('portuguese'))\n",
        "\n",
        "# Definir stopwords personalizadas\n",
        "stopwords_personalizadas = set(['a', 'agora', 'algum', 'alguma', 'aquele', 'aqueles', 'de', 'deu', 'do',\n",
        "                                 'e', 'estou', 'esta', 'ir', 'meu', 'muito', 'mesmo', 'no', 'nossa',\n",
        "                                 'o', 'outro', 'para', 'que', 'sem', 'tem', 'porque', 'não', 'acredito'])\n",
        "\n",
        "# Combinar stopwords do NLTK com stopwords personalizadas\n",
        "todas_stopwords = stop_words.union(stopwords_personalizadas)\n",
        "\n",
        "# Definir a função de cores aleatórias\n",
        "def cores_personalizadas(word, font_size, position, orientation, random_state=None, **kwargs):\n",
        "    return random.choice(['#C9184A', '#FF4D6D', '#FF758F'])\n",
        "\n",
        "# Carregar os dados do Excel\n",
        "df = pd.read_excel('nuvemlovelace.xlsx')\n",
        "\n",
        "# Verificar se a coluna \"frases\" existe\n",
        "if 'frases' in df.columns:\n",
        "    # Concatenar todas as frases em uma única string\n",
        "    texto = ' '.join(df['frases'].dropna().astype(str).tolist())\n",
        "\n",
        "    # Remover stopwords\n",
        "    palavras = [word for word in texto.split() if word.lower() not in todas_stopwords]\n",
        "    texto_sem_stopwords = ' '.join(palavras)\n",
        "\n",
        "    # Carregar a imagem de máscara\n",
        "    mascara = np.array(Image.open('mulhernuvem.png'))\n",
        "\n",
        "    # Gerar a nuvem de palavras com a máscara e aplicar a função de cores personalizadas\n",
        "    wordcloud = WordCloud(width=800, height=400,\n",
        "                          background_color='white',\n",
        "                          mask=mascara,\n",
        "                          contour_color='pink',\n",
        "                          contour_width=1,\n",
        "                          color_func=cores_personalizadas).generate(texto_sem_stopwords)\n",
        "\n",
        "    # Exibir a nuvem de palavras\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis('off')  # Remove os eixos\n",
        "    plt.show()\n",
        "\n",
        "     # Salvar a nuvem de palavras em um arquivo\n",
        "    wordcloud.to_file('nuvem_de_palavras.png')\n",
        "else:\n",
        "    print(\"A coluna 'frases' não foi encontrada na planilha.\")"
      ],
      "metadata": {
        "id": "Zc34bIx-BIwc"
      },
      "execution_count": 43,
      "outputs": []
    }
  ]
}